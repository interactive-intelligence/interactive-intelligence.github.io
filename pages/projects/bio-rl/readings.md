---
layout: default
title: Readings and Resources
parent: Bio-RL
grand_parent: Projects
nav_order: 2
has_children: false
permalink: /projects/bio-rl/readings
---

# Readings
{: .no_toc }

Papers, articles, and other material we have learned and used in development
{: .fs-6 .fw-300 }

---

## RL Algorithms
["Policy Gradient"](https://towardsdatascience.com/an-intuitive-explanation-of-policy-gradient-part-1-reinforce-aa4392cbfd3c){:target="_blank"} Article by Adrien Lucas Ecoffet on the math behind the loss and update rule for policy gradient.
["Policy Gradient"](https://towardsdatascience.com/policy-gradients-in-a-nutshell-8b72f9743c5d){:target="_blank"} Article by Sanyam Kapoor, another helpful explanation of the math of policy gradient algorithms.
["Policy Gradient and Actor Critic"](https://www.youtube.com/watch?v=bRfUxQs6xIM){:target="_blank"} A fantastic lesson by Hado Van Hasselt of Deepmind on all things Actor Critic and RL.
["PyTorch Actor Critic"](https://github.com/hermesdt/reinforcement-learning/blob/master/a2c/cartpole_a2c_online.ipynb){:target="_blank"} By Github user hermesdt: Code we followed to create our own variants of Actor Critic methods with OpenAI gym.
["Trust Region Policy Optimization"](https://jonathan-hui.medium.com/rl-trust-region-policy-optimization-trpo-explained-a6ee04eeeee9){:target="_blank"} By Jonathan Hui: an intuitive explanation of Trust Region Policy Optimization.

## Neuroscience
["A Thousand Brains: A New Theory of Intelligence"](https://www.amazon.com/Thousand-Brains-New-Theory-Intelligence/dp/1541675819){:target="_blank"} By Jeff Hawkins of Numenta, explaining his theory of cognition and cortical columns.
["Models of the Mind"](https://www.amazon.com/Models-Mind-Engineering-Mathematics-Understanding/dp/1472966422){:target="_blank"} By Grace Lindsay, a tour of the mathematical models most useful to computational neuroscience when describing the brain.






*More research and resources forthcoming.*

